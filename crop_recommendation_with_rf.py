# -*- coding: utf-8 -*-
"""crop recommendation with RF

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PfVvZ43MKHY5T3x1GUrunAtUB-41R-WI
"""

#importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("Crop_recommendation.csv")
df.head()

#EXPLORATORY DATA ANALYSIS
df.shape

df.info()

df.describe()

df.columns

df["label"].unique()

df["label"].value_counts()

label_counts = df["label"].value_counts()

# Plotting the pie chart
plt.figure(figsize=(8, 8))
label_counts.plot.pie(autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired.colors)
plt.title('Label Distribution')
plt.show()

plt.figure(figsize=(8, 6))
sns.scatterplot(x=df["rainfall"], y=df["temperature"])
plt.title('Relationship between Rainfall and Temperature')
plt.xlabel('Rainfall')
plt.ylabel('Temperature')
plt.show()

df["temperature"].describe()

df["rainfall"].describe()

plt.figure(figsize=(8, 6))
sns.scatterplot(x=df["rainfall"], y=df["humidity"])
plt.title('Relationship between Rainfall and Humidity')
plt.xlabel('Rainfall')
plt.ylabel('Humidity')
plt.show()

"""**Modeling**"""

from sklearn.model_selection import train_test_split  # For splitting the data
from sklearn.ensemble import RandomForestClassifier   # The Random Forest classifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

class_labels = df['label'].unique().tolist()
class_labels

from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder

le = LabelEncoder()
df['label'] = le.fit_transform(df['label'])

df['label']

df

x = df.drop('label',axis=1)
y = df['label']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(x_train, y_train)

from sklearn.model_selection import GridSearchCV
rf = RandomForestClassifier()

# Define the parameter grid
param_grid = {
    'n_estimators': [100, 200, 300],          # Number of trees in the forest
    'max_depth': [None, 10, 20, 30],          # Maximum depth of each tree
    'min_samples_split': [2, 5, 10],          # Minimum number of samples required to split an internal node
    'min_samples_leaf': [1, 2, 4],            # Minimum number of samples required to be at a leaf node
    'bootstrap': [True, False]                # Whether bootstrap samples are used when building trees
}

# Set up the GridSearchCV
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Fit the model
grid_search.fit(x_train, y_train)

# Get the best parameters and best score
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

best_rf = grid_search.best_estimator_
test_score = best_rf.score(x_test, y_test)
print("Test Set Score:", test_score)

#feature importance

feature_importances = grid_search.best_estimator_.feature_importances_  # Access feature importances from the fitted best estimator
feature_names = x

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(range(len(feature_importances)), feature_importances, align='center')
plt.yticks(np.arange(len(feature_importances)), feature_names)
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importance in Random Forest')
plt.show()

#CHECKING WHAT CROP EACH NUMBER REPRESENT
label_dict = {}
for index,label in enumerate(class_labels):
    label_dict[label] = index

print(label_dict)

"""The code above shows what crop each number represents from 0-20"""



"""Now, let us try some predictions with our highly performing model

Firstly,we will create a Pandas Series named pred_series with values initialized to zero. The length of the Series matches the number of columns in features_data['columns'], and each entry is indexed by the corresponding column name. This Series can be used to store or manipulate values related to each feature in the dataset
"""

#creating a feature_data list
features_data = {'columns':list(x.columns)}

#creating a pandas series
pred_series = pd.Series(np.zeros(len(features_data['columns'])),index=features_data['columns'])
pred_series

"""We will input random numbers into the generated series above to see what crop the model predicts with these inputs"""

pred_series['N'] = 20
pred_series['P'] = 12
pred_series['K'] = 13
pred_series['temperature'] = 32
pred_series['humidity'] = 45
pred_series['ph'] = 5
pred_series['rainfall'] = 280

output = best_rf.predict([pred_series])[0]
print("Recommended Crop:",class_labels[output])

"""**Therefore, with the above environmental conditions or inputs, the recommended crop by the model is "JUTE".**"""

#save the model in joblib
import joblib
joblib.dump(best_rf,'crop_recommendation_model.joblib')

